#!/usr/bin/env python
import os

import configparser
import feedparser
import urllib
import re
import time
import sys
import threading
from twitter import Twitter, OAuth

TWITTER_CONSIDERED_URL_LENGHT = 23
TWEET_MAX_LENGHT = 280
og_image_pattern = re.compile('.*og:image" content="(.*?)".*?\/>')


class Feed(object):
    """
    Base class for feeds.
    Contains all the logic to do authentication on twitter service.
    Each class that inherits must implements process_tweets on his own.
    dry_run method is optional. Just needed to do testing.
    """
    def __init__(self, config, section):
        self.oauth_token = config.get(section, 'oauth_token')
        self.oauth_token_secret = config.get(section, 'oauth_token_secret')
        self.oauth_consumer_key = config.get(section, 'oauth_consumer_key')
        self.oauth_consumer_secret = config.get(section, 'oauth_consumer_secret')
        self.dry_run = config.getboolean(section, 'dry_run')
        self.intervals_between_tweets_in_seconds = config.getint(section, 'intervals_between_tweets_in_seconds')
        self.num_last_tweets = config.getint(section, 'num_last_tweets')
        # Auth Credentials
        self.oauth = OAuth(self.oauth_token, self.oauth_token_secret, self.oauth_consumer_key, self.oauth_consumer_secret)
        self.twitter_api = Twitter(auth=self.oauth)
        self.twitter_upload_api = Twitter(auth=self.oauth, domain='upload.twitter.com')

    def process_tweets(self):
        raise NotImplementedError

    def __str__(self):
        return str(self.__dict__)


class FileFeed(Feed):
    def __init__(self, config, section):
        super(FileFeed, self).__init__(config, section)
        self.feed_path = config.get(section, 'feed_path')
        self.load_tweets()

    def load_tweets(self):
        if not os.path.isfile(self.feed_path):
            raise IOError("%s is not a file", self.feed_path)

        with open(self.feed_path, 'r') as tweets_file:
            self.tweets = tweets_file.readlines()

        if len(self.tweets) == 0:
            raise IOError("%s file is empty ", self.feed_path)

    def tweet_is_valid(self, tweet):
        """
        Checks if tweet is valid, measuring the length for every tweet and checking
        how much space will use each url in the tweet content.
        :param tweet:
        :return: True if tweet length will be correct. False otherwise
        """
        tweet_length = len(tweet)

        if tweet_length == 0:
            return False

        if tweet_length > TWEET_MAX_LENGHT:
            urls = re.findall('https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?', tweet)
            if len(urls) == 0:
                return False

            urls_real_length = 0
            for url in urls:
                urls_real_length += len(url)
            tweet_length -= urls_real_length
            tweet_length += len(urls) * TWITTER_CONSIDERED_URL_LENGHT
            return tweet_length < TWEET_MAX_LENGHT
        return True

    def process_tweets(self):
        print("Processing from FileFeed")
        for index, tweet in enumerate(self.tweets):
            if self.tweet_is_valid(tweet):
                if self.dry_run:
                    print "[DRY-RUN (", index, ")] ", "sleep(", self.intervals_between_tweets_in_seconds, ") ", tweet, ")\n"
                else:
                    self.twitter_api.statuses.update(status=tweet)
            else:
                print "The tweet located in ", self.feed_path, " line ", index, " isn't valid."
                continue

            # Checking if file feed still exists.
            if not os.path.isfile(self.feed_path):
                break

            if self.intervals_between_tweets_in_seconds > 0 or index != len(self.tweets):
                if not self.dry_run:
                    time.sleep(self.intervals_between_tweets_in_seconds)


class URLFeed(Feed):
    def __init__(self, config, section):
        super(URLFeed, self).__init__(config, section)
        self.feed_url = config.get(section, 'feed_url')
        self.attach_featured_images = config.getboolean(section, 'attach_featured_images')
        self.max_days_in_rotation = config.getint(section, 'max_days_in_rotation')
        if self.max_days_in_rotation != -1:
            self.max_seconds_in_rotation = self.max_days_in_rotation * 24 * 60 * 60

    def process_tweets(self):
        feed_dict = feedparser.parse(self.feed_url)
        num_tweets = min(self.num_last_tweets, len(feed_dict.entries))

        if self.dry_run and num_tweets is 0:
            print "[DRY-RUN] Got", num_tweets,"tweets"
            print feed_dict.headers
            print feed_dict
            print self
                
        for i in xrange(num_tweets):
            entry = feed_dict.entries[i]
            title = entry.title
            if len(title) > 231:
                title = title[:231]+'...'

            seconds_old = time.mktime(entry.published_parsed)
            now = time.time()
            if (now-seconds_old) > self.max_seconds_in_rotation:
                if self.dry_run:
                    print "[DRY-RUN (", i, ")] skipping (too old) ", title
                continue
                            
            if self.attach_featured_images:
                featured_image_url = URLFeed.scrape_entry_og_image(entry)

                if featured_image_url is not None:
                    if not self.dry_run:
                        img_data = URLFeed.download_image(featured_image_url)
                        img_id = self.twitter_upload_api.media.upload(media=img_data)["media_id_string"]
                        self.twitter_api.statuses.update(status=title + " " + entry.link, media_ids = img_id) # Call twitter API
                    else:
                        print "[DRY-RUN (", i, ")] ", title + " " + entry.link, " (+img attachment - ", featured_image_url, ")"
                        print "[DRY-RUN (", i, ")] time() -> ", time.mktime(entry.published_parsed)
                        img_data = URLFeed.download_image(featured_image_url)
                        print "[DRY-RUN (", i, ")] ", len(img_data)
                else:
                    print "Could not scrape featured image url from ", entry.link, " (regex might need maintenance)"
            else:
                if not self.dry_run:
                    self.twitter_api.statuses.update(status=title + " " + entry.link) # Call twitter API
                else:
                    print "[DRY-RUN (", i, ")] ", title + " " + entry.link

            if self.intervals_between_tweets_in_seconds > 0:
                if not self.dry_run:
                    time.sleep(self.intervals_between_tweets_in_seconds)
                else:
                    print "[DRY-RUN (", i, ")] ", "sleep(", self.intervals_between_tweets_in_seconds,")\n"

    @staticmethod
    def scrape_entry_og_image(entry):
        """
        Download a feed's entry HTML and parse it to find the og:image in the entry if available.

        :param entry:
        :return: the url of the featured image if found, otherwise None
        """
        featured_image_url = None
        f = urllib.urlopen(entry.link)
        html = f.read()
        f.close()
        match = og_image_pattern.search(html)
        if match is not None:
            featured_image_url = match.group(1)
        return featured_image_url

    @staticmethod
    def download_image(img_url):
        file_path = "image.tmp"
        urllib.urlretrieve(img_url, file_path)
        f = open(file_path,'rb')
        img_data = f.read()
        f.close()
        return img_data


def load_config(configFile='config.conf'):
    """
    Returns a configparser object that contains all the configuration for the different blogs and twitter accounts.
    :param configFile:
    :return:
    """
    config = configparser.ConfigParser()
    config.read(configFile)
    return config


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print "Error: config file path not passed.\n"
        sys.exit(1)
        
    config = load_config(sys.argv[1])
    for section_name in config.sections():
        try:
            feed = URLFeed(config, section_name)
        except configparser.NoOptionError:
            feed = FileFeed(config, section_name)

        thread = threading.Thread(target=feed.process_tweets)
        thread.daemon = False
        thread.start()
